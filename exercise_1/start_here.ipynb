{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Exercise Demo\n",
    "\n",
    "This notebook contains the first exercise of the Machine Learning for Visual Computing (183.605) lecture at TU Wien. Assignment via TUWEL. Please be aware of the deadlines in TUWEL.\n",
    "\n",
    "* Upload a zip-file with the required programms. The programming language is python. **Please update your group number in the filename (_X)** and only upload your solutions folder.\n",
    "    1. Single Layer Perceptron --> `solutions_G_X/perceptron.py`\n",
    "    2. Support Vector Machine --> `solutions_G_X/svm.py`\n",
    "    3. Multi Layer Perceptron --> `solutions_G_X/mlp.py`\n",
    "* If you needed additional conda or pip packages add an anaconda environment.yml to the zip-file\n",
    "    1. conda env export > environment.yml\n",
    "    2. See --> https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#sharing-an-environment\n",
    "\n",
    "##### Conda instructions\n",
    "\n",
    "1. conda create --name MLVC\n",
    "4. conda activate MLVC\n",
    "5. conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "6. python -m pip install pillow matplotlib tqdm torchinfo pandas ipykernel nbformat ipywidgets scikit-learn tabulate cvxopt seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# General setting for the ipynb\n",
    "NUM_SAMPLES = 10000     # Number of training samples that will be generated\n",
    "TEST_RATIO = 0.9        # Percentage of the generated samples that are used for training (rest is used for testing). [0, 1]\n",
    "EPOCHS_Perceptron = 1000# Amount of training epochs for the single layer perceptron\n",
    "EPOCHS_MLP = 10         # Amount of training epochs for the multi layer perceptron\n",
    "\n",
    "LR_SLP = 0.1            # Learning rate of the SLP\n",
    "LR_MLP = 0.01           # Learning rate of the MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset using numpy and pillow\n",
    "\n",
    "from utils import Dataset\n",
    "(dataset_train, labels_train), (dataset_test, labels_test) = Dataset(NUM_SAMPLES, TEST_RATIO)\n",
    "\n",
    "fig, axs = plt.subplots(2, 8, figsize=(8, 2), dpi=200)\n",
    "\n",
    "for i, ax in enumerate(axs.reshape(-1)):\n",
    "    ax.imshow(dataset_train[i,:].reshape((16, 16)), cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(\"Circle\" if labels_train[i] == -1 else \"Square\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(dataset_train.shape, labels_train.shape, dataset_test.shape, labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron (10 Points)\n",
    "\n",
    "The following code works only, if corresponding definitions in the 'solutions' folder are complete. Look at the 'ToDo' comments in the corresponding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_G_X import Perceptron\n",
    "from utils import plot_results_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(lr=LR_SLP, epochs=EPOCHS_Perceptron)\n",
    "\n",
    "miss_list = perceptron.fit(dataset_train, labels_train)\n",
    "\n",
    "# convert the miss_list to a miss_rate\n",
    "miss_list = np.array(miss_list)\n",
    "miss_list = miss_list / dataset_train.shape[0]\n",
    "\n",
    "y_pred = perceptron.predict(dataset_test)\n",
    "\n",
    "plot_results_perceptron(perceptron.w, miss_list, labels_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Expected Results (Trained: 10.000 Samples, 1000 Epochs, 0.1 LR)\n",
    "Left: Example weights of the Perceptron.\n",
    "\n",
    "Middle: Example graph of the missclassifications during training, per epoch.\n",
    "\n",
    "Right: Confusion matrix of the trained Perceptron.\n",
    "\n",
    "**Note**: As the Perceptron is not capable of separating the data, we do not expect a high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex; justify-content:center; background-color:white;\">\n",
    "  <div style=\"text-align:center; padding:10px;\">\n",
    "    <img src=\"imgs/weights_and_missclassifications_SLP.png\" style=\"height:100%; width:auto;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine (20 Points)\n",
    "\n",
    "The following code works only if corresponding definitions in the 'solutions' folder are complete. Look at the 'ToDo' comments in the corresponding files.\n",
    "\n",
    "#### Reduce Training Data for SVM for performance reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take 500 examples for SVM for performance reasons\n",
    "dataset_train_svm = dataset_train[:500]\n",
    "labels_train_svm = labels_train[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example SVM Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from utils import plot_results_svm\n",
    "\n",
    "classifier_rbf = SVC(kernel = 'rbf')\n",
    "classifier_rbf.fit(dataset_train_svm, labels_train_svm)\n",
    "\n",
    "y_pred_rbf = classifier_rbf.predict(dataset_test)\n",
    "\n",
    "classifier_linear = SVC(kernel = 'linear')\n",
    "classifier_linear.fit(dataset_train_svm, labels_train_svm)\n",
    "\n",
    "y_pred_linear = classifier_linear.predict(dataset_test)\n",
    "\n",
    "plot_results_svm(labels_test, y_pred_rbf, y_pred_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_G_X import SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_linear = SVM(kernel=\"linear\")\n",
    "classifier_linear.fit(dataset_train_svm, labels_train_svm)\n",
    "y_pred_linear = classifier_linear.predict(dataset_test)\n",
    "\n",
    "classifier_rbf = SVM(kernel=\"rbf\", sigma=0.25)\n",
    "classifier_rbf.fit(dataset_train_svm, labels_train_svm)\n",
    "y_pred_rbf = classifier_rbf.predict(dataset_test)\n",
    "\n",
    "plot_results_svm(labels_test, y_pred_rbf, y_pred_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Expected Results (Trained: 500 Samples)\n",
    "Left: Confustion matrix of the trained linear SVM.\n",
    "\n",
    "Right: Confusion matrix of the trained RBF SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex; justify-content:center; background-color:white;\">\n",
    "  <div style=\"text-align:center; padding:10px;\">\n",
    "    <img src=\"imgs/cm_SVM.png\" style=\"height:100%; width:auto;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi Layer Perceptron (20 Points)\n",
    "\n",
    "#### Convert Dataset to PyTorch\n",
    "\n",
    "This sub-section contains an experiment using the pytorch MLP as a reference. The next sub-section calls your own functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Dataset_PyTorch\n",
    "\n",
    "dataloader_train, dataloader_test = Dataset_PyTorch(dataset_train, labels_train, dataset_test, labels_test, batch_size=1)\n",
    "fig, axs = plt.subplots(2, 8, figsize=(8, 2), dpi=200)\n",
    "axs = axs.reshape(-1)\n",
    "for i, (x, y) in enumerate(dataloader_train):\n",
    "    axs[i].imshow(x.reshape((16, 16)), cmap=\"gray\")\n",
    "    axs[i].set_title(\"Circle\" if y.cpu().numpy() == 0 else \"Square\")\n",
    "    axs[i].axis('off')\n",
    "\n",
    "    if i == 15:\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Multi-layer Preceptron Implementation in PyTorch\n",
    "\n",
    "For simplicity the resulting training plot is shown below, as training the MLP with a batch size of 1 takes a long time. However, you can try it yourself and experiment with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import MLP, train, evaluate, vis_loss_and_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(256, 1)\n",
    "\n",
    "print(summary(model, input_size=(1, 256)))\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR_MLP)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "loss_train_plot = []\n",
    "loss_test_plot = []\n",
    "acc_train_plot = []\n",
    "acc_test_plot = []\n",
    "\n",
    "with trange(EPOCHS_MLP, position=0, leave=True) as tepoch:\n",
    "    for epoch in tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        train_loss, train_acc = train(model, dataloader_train, optimizer, criterion, device)\n",
    "        test_loss, test_acc = evaluate(model, dataloader_test, criterion, device)\n",
    "\n",
    "        loss_train_plot.append(train_loss)\n",
    "        loss_test_plot.append(test_loss)\n",
    "        acc_train_plot.append(train_acc*100)\n",
    "        acc_test_plot.append(test_acc*100)\n",
    "\n",
    "        tepoch.set_postfix(loss_test=test_loss, accuracy_test=test_acc*100, loss_train=train_loss, accuracy_train=train_acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize loss, accuracy and weights of the PyTorch MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_loss_and_weights(loss_train_plot, loss_test_plot, acc_train_plot, acc_test_plot, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resulting plot of the PyTorch MLP training\n",
    "\n",
    "<div style=\"display:flex; justify-content:center; background-color:white;\">\n",
    "  <div style=\"text-align:center; padding:10px;\">\n",
    "    <img src=\"imgs/results_mlp.png\" style=\"height:100%; width:auto;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Implementation of the Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_G_X import MultiLayerPerceptron\n",
    "from utils import plot_results_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MultiLayerPerceptron(epochs=EPOCHS_MLP, activation=\"sigmoid\", lr=LR_MLP, weight_init=\"xavier\")\n",
    "\n",
    "MLP.fit(dataset_train, labels_train, dataset_test, labels_test)\n",
    "\n",
    "plot_results_mlp(MLP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLVC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
